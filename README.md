# A/B Testing Statistical Framework

![Tests](https://github.com/galafis/ab-testing-statistical-framework-python/workflows/Tests/badge.svg)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![SciPy](https://img.shields.io/badge/SciPy-8CAAE6?style=for-the-badge&logo=scipy&logoColor=white) ![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white) ![Statistics](https://img.shields.io/badge/Statistics-FF6B6B?style=for-the-badge)

---

## üáßüá∑ Framework Estat√≠stico para Testes A/B

Este reposit√≥rio fornece um framework completo e profissional para **A/B Testing**, combinando abordagens **frequentista** e **bayesiana**. √â uma ferramenta essencial para cientistas de dados, analistas de produto e growth hackers que precisam tomar decis√µes baseadas em dados com rigor estat√≠stico.

### üéØ Objetivo

Fornecer um toolkit robusto e bem documentado para conduzir testes A/B de forma profissional, incluindo c√°lculo de tamanho de amostra, testes de hip√≥tese, an√°lise bayesiana e interpreta√ß√£o de resultados.

### üåü Por que este Framework?

A/B Testing √© fundamental para:

- **Product Development**: Validar features antes do lan√ßamento completo
- **Marketing**: Otimizar campanhas, CTAs e landing pages
- **E-commerce**: Aumentar convers√£o e receita
- **UX/UI**: Melhorar experi√™ncia do usu√°rio baseado em dados
- **Growth**: Tomar decis√µes data-driven para crescimento

### üìä Abordagens Estat√≠sticas

#### Frequentista vs Bayesiana

| Aspecto | Frequentista | Bayesiana |
|---------|--------------|-----------|
| **Filosofia** | Probabilidade como frequ√™ncia de longo prazo | Probabilidade como grau de cren√ßa |
| **Output** | P-valor e intervalo de confian√ßa | Probabilidade de B > A |
| **Interpreta√ß√£o** | Rejeitar ou n√£o H‚ÇÄ | Probabilidade direta do resultado |
| **Stopping Rule** | Deve ser definido antes | Pode parar quando quiser |
| **Prior Knowledge** | N√£o utiliza | Incorpora conhecimento pr√©vio |

### üìÇ Estrutura do Reposit√≥rio

```
ab-testing-statistical-framework-python/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ hypothesis_testing/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ ab_test.py             # Framework principal
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_ab_framework.py       # Testes unit√°rios
‚îú‚îÄ‚îÄ images/                        # Visualiza√ß√µes geradas
‚îú‚îÄ‚îÄ setup.py                       # Configura√ß√£o de instala√ß√£o
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ README.md
```

### üöÄ Instala√ß√£o e Uso

```bash
# Clone o reposit√≥rio
git clone https://github.com/galafis/ab-testing-statistical-framework-python.git

# Navegue at√© o diret√≥rio
cd ab-testing-statistical-framework-python

# Instale as depend√™ncias
pip install -r requirements.txt

# Execute o exemplo
python src/hypothesis_testing/ab_test.py
```

**Sa√≠da esperada:**
```
Sample Size Calculation:
------------------------------------------------------------
Required sample size per group: 3841

============================================================
A/B TEST RESULTS (FREQUENTIST)
============================================================
Conversion Rate A: 0.0800
Conversion Rate B: 0.0967
Absolute Difference: 0.0167
Relative Lift: 20.83%
Z-Statistic: 1.6084
P-Value: 0.1077
Significant: False
95% CI: (-0.0036, 0.0370)
============================================================

============================================================
A/B TEST RESULTS (BAYESIAN)
============================================================
Probability B > A: 94.38%
Probability A > B: 5.62%
Expected Loss (choosing B): 0.000248
Expected Loss (choosing A): 0.016875
============================================================
```

### üìù Exemplos de Uso

#### 1. C√°lculo de Tamanho de Amostra

Antes de iniciar um teste A/B, √© crucial calcular quantos usu√°rios voc√™ precisa:

```python
from src.hypothesis_testing.ab_test import ABTest

# Inicializar framework
ab_test = ABTest(alpha=0.05, power=0.80)

# Calcular tamanho de amostra necess√°rio
sample_size = ab_test.calculate_sample_size(
    baseline_rate=0.10,      # Taxa de convers√£o atual: 10%
    mde=0.20,                # Efeito m√≠nimo detect√°vel: 20% de melhoria
    ratio=1.0                # Propor√ß√£o 1:1 entre controle e tratamento
)

print(f"Voc√™ precisa de {sample_size} usu√°rios por grupo")
# Output: Voc√™ precisa de 3841 usu√°rios por grupo
```

#### 2. Teste Frequentista (Z-Test)

```python
# Dados do teste
conversions_a = 120    # Convers√µes no grupo A (controle)
visitors_a = 1500      # Visitantes no grupo A

conversions_b = 145    # Convers√µes no grupo B (tratamento)
visitors_b = 1500      # Visitantes no grupo B

# Executar teste
results = ab_test.two_proportion_ztest(
    conversions_a, visitors_a,
    conversions_b, visitors_b
)

# Imprimir resultados
ab_test.print_results(results, 'frequentist')
```

#### 3. Teste Bayesiano

```python
# Executar an√°lise bayesiana
bayes_results = ab_test.bayesian_ab_test(
    conversions_a, visitors_a,
    conversions_b, visitors_b,
    n_simulations=100000
)

# Imprimir resultados
ab_test.print_results(bayes_results, 'bayesian')
```

### üéì Conceitos Estat√≠sticos

| Conceito | Defini√ß√£o | Valor T√≠pico |
|----------|-----------|--------------|
| **Alpha (Œ±)** | Probabilidade de erro tipo I (falso positivo) | 0.05 (5%) |
| **Beta (Œ≤)** | Probabilidade de erro tipo II (falso negativo) | 0.20 (20%) |
| **Power (1-Œ≤)** | Probabilidade de detectar efeito real | 0.80 (80%) |
| **MDE** | Minimum Detectable Effect (menor efeito detect√°vel) | 10-20% |
| **P-value** | Probabilidade de observar resultado se H‚ÇÄ for verdadeira | < 0.05 para signific√¢ncia |

### üîß Funcionalidades do Framework

| Funcionalidade | Descri√ß√£o | M√©todo |
|----------------|-----------|--------|
| **Sample Size Calculation** | Calcula n necess√°rio | `calculate_sample_size()` |
| **Z-Test** | Teste frequentista de duas propor√ß√µes | `two_proportion_ztest()` |
| **Bayesian Test** | An√°lise bayesiana com Beta distributions | `bayesian_ab_test()` |
| **Confidence Intervals** | Intervalos de confian√ßa para diferen√ßa | Inclu√≠do no Z-test |
| **Expected Loss** | Perda esperada de cada decis√£o | Inclu√≠do no Bayesian |
| **Relative Lift** | Percentual de melhoria | Calculado automaticamente |

### üß™ Testes

O framework possui uma suite completa de testes com **83%+ de cobertura**:

```bash
# Executar todos os testes
pytest tests/ -v

# Executar com relat√≥rio de cobertura
pytest tests/ --cov=src --cov-report=term-missing
```

**Testes incluem:**
- Testes unit√°rios para todas as fun√ß√µes principais
- Testes de integra√ß√£o para workflows completos
- Testes de casos extremos (edge cases)
- Valida√ß√£o de precis√£o estat√≠stica

### ü§ù Como Contribuir

Contribui√ß√µes s√£o bem-vindas! Por favor, leia o [CONTRIBUTING.md](CONTRIBUTING.md) para detalhes sobre nosso c√≥digo de conduta e processo de submiss√£o de pull requests.

**Passos para contribuir:**
1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## üá¨üáß A/B Testing Statistical Framework

This repository provides a complete and professional framework for **A/B Testing**, combining **frequentist** and **Bayesian** approaches.

### üöÄ Installation and Usage

```bash
git clone https://github.com/galafis/ab-testing-statistical-framework-python.git
cd ab-testing-statistical-framework-python
pip install -r requirements.txt
python src/hypothesis_testing/ab_test.py
```

---

**Author:** Gabriel Demetrios Lafis  
**License:** MIT  
**Last Updated:** February 2026
